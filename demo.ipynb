{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"demo.ipynb","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"f07bb12e838842a184d08ceae4df106c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d2c2ae4c30fe41d2916ca9cfc356ba57","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ca3a39ffbdcb41c18132abbc973c1530","IPY_MODEL_4ba148cdfe16404da3d8b41673d2722f","IPY_MODEL_e80fbd7c39d740028f9fc05bbea97e42"]}},"d2c2ae4c30fe41d2916ca9cfc356ba57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca3a39ffbdcb41c18132abbc973c1530":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d09270ef377f4014b3f7953d9f0c0606","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95ae6cabd0824296afecff5222614458"}},"4ba148cdfe16404da3d8b41673d2722f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_51480be6b9ad44ef93ffa3326e55071b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":665,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":665,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2e0e04f5bce45369c3dce66d4972b36"}},"e80fbd7c39d740028f9fc05bbea97e42":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2cfc5edb570e42b09782a469387bcac9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 665/665 [00:00&lt;00:00, 19.1kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba633b0747b94f8692cae32f163fda07"}},"d09270ef377f4014b3f7953d9f0c0606":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95ae6cabd0824296afecff5222614458":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51480be6b9ad44ef93ffa3326e55071b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b2e0e04f5bce45369c3dce66d4972b36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2cfc5edb570e42b09782a469387bcac9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba633b0747b94f8692cae32f163fda07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"306c8cd79ab14592abee7abe64bb1afa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d999bc0096824728b48bf8e44a27e9f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6d4af0f6e67c4555b75f4540463b3fb9","IPY_MODEL_cc3099f4f7b84170889110d768808a28","IPY_MODEL_9e376dd0111149c3a8559adc3436ed19"]}},"d999bc0096824728b48bf8e44a27e9f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6d4af0f6e67c4555b75f4540463b3fb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67dc8ea0909e400c982e8b4e7c9d7b1c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73471cb88bca461d9e8eb410834e0d61"}},"cc3099f4f7b84170889110d768808a28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f7faa1075a234ae9b3ef095319db84f7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":548118077,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":548118077,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d019c32f7fc74f9386e47db9a1e190ee"}},"9e376dd0111149c3a8559adc3436ed19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21963580804245c58fa5669f75498c20","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 523M/523M [00:17&lt;00:00, 33.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee7f99e3e61c4e27b0a867bb0783a186"}},"67dc8ea0909e400c982e8b4e7c9d7b1c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"73471cb88bca461d9e8eb410834e0d61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7faa1075a234ae9b3ef095319db84f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d019c32f7fc74f9386e47db9a1e190ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21963580804245c58fa5669f75498c20":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ee7f99e3e61c4e27b0a867bb0783a186":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"iq-T3wt1l9uN"},"source":["# Pretrained Transformers as Universal Computation Engines Demo\n","\n","This is a demo notebook illustrating creating a Frozen Pretrained Transformer (FPT) and training on the Bit XOR task, which converges within a couple minutes.\n","\n","arXiv: https://arxiv.org/pdf/2103.05247.pdf\n","\n","Github: https://github.com/kzl/universal-computation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfSqNWXDmRmF","executionInfo":{"status":"ok","timestamp":1637197909119,"user_tz":300,"elapsed":7013,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"1a0db319-835c-4575-f314-6954467d9bf0"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 5.2 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 53.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 48.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"]}]},{"cell_type":"code","metadata":{"id":"ekU90bOpl9uR","executionInfo":{"status":"ok","timestamp":1637197914747,"user_tz":300,"elapsed":2728,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","from transformers.models.gpt2.modeling_gpt2 import GPT2Model"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ueVzKyyl9uU"},"source":["## Creating the dataset\n","\n","For this demo, we'll look at calculating the elementwise XOR between two randomly generated bitstrings.\n","If you want to play more with the model, feel free to try larger $n$, although it will take longer to train."]},{"cell_type":"code","metadata":{"id":"0_2bJ2SSl9uV","executionInfo":{"status":"ok","timestamp":1637197922951,"user_tz":300,"elapsed":123,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["def generate_example(n):\n","    bits = np.random.randint(low=0, high=2, size=(2, n))\n","    xor = np.logical_xor(bits[0], bits[1]).astype(np.long)\n","    return bits.reshape((2*n)), xor"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_lEE6uol9uV","executionInfo":{"status":"ok","timestamp":1637197923513,"user_tz":300,"elapsed":132,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"4a3daf5c-b7e9-4eb6-8b62-acff7f5981f6"},"source":["n = 5\n","bits, xor = generate_example(n)\n","\n","print('  String 1:', bits[:n])\n","print('  String 2:', bits[n:])\n","print('Output XOR:', xor)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["  String 1: [0 1 1 0 0]\n","  String 2: [1 1 0 0 1]\n","Output XOR: [1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"uD7CO9Irl9uW"},"source":["## Creating the frozen pretrained transformer\n","\n","We simply wrap a pretrained GPT-2 model with linear input and output layers, then freeze the weights of the self-attention and feedforward layers.\n","You can also see what happens using a randomly initialized model instead."]},{"cell_type":"code","metadata":{"id":"kUo5Q5tRl9uX","executionInfo":{"status":"ok","timestamp":1637197932828,"user_tz":300,"elapsed":175,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["f07bb12e838842a184d08ceae4df106c","d2c2ae4c30fe41d2916ca9cfc356ba57","ca3a39ffbdcb41c18132abbc973c1530","4ba148cdfe16404da3d8b41673d2722f","e80fbd7c39d740028f9fc05bbea97e42","d09270ef377f4014b3f7953d9f0c0606","95ae6cabd0824296afecff5222614458","51480be6b9ad44ef93ffa3326e55071b","b2e0e04f5bce45369c3dce66d4972b36","2cfc5edb570e42b09782a469387bcac9","ba633b0747b94f8692cae32f163fda07","306c8cd79ab14592abee7abe64bb1afa","d999bc0096824728b48bf8e44a27e9f0","6d4af0f6e67c4555b75f4540463b3fb9","cc3099f4f7b84170889110d768808a28","9e376dd0111149c3a8559adc3436ed19","67dc8ea0909e400c982e8b4e7c9d7b1c","73471cb88bca461d9e8eb410834e0d61","f7faa1075a234ae9b3ef095319db84f7","d019c32f7fc74f9386e47db9a1e190ee","21963580804245c58fa5669f75498c20","ee7f99e3e61c4e27b0a867bb0783a186"]},"id":"eYtLKrk9l9uY","executionInfo":{"status":"ok","timestamp":1637197955231,"user_tz":300,"elapsed":20514,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"2c215222-a6bb-48aa-9aa0-fea6130c9235"},"source":["gpt2 = GPT2Model.from_pretrained('gpt2')  # loads a pretrained GPT-2 base model\n","in_layer = nn.Embedding(2, 768)           # map bit to GPT-2 embedding dim of 768\n","out_layer = nn.Linear(768, 2)             # predict logits"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f07bb12e838842a184d08ceae4df106c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"306c8cd79ab14592abee7abe64bb1afa","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"8er6uND0l9uY","executionInfo":{"status":"ok","timestamp":1637197955233,"user_tz":300,"elapsed":16,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["for name, param in gpt2.named_parameters():\n","    # freeze all parameters except the layernorm and positional embeddings\n","    if 'ln' in name or 'wpe' in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jlr912WNl9uZ"},"source":["## Training loop\n","\n","We train the model with stochastic gradient descent on the Bit XOR task.\n","The model should converge within 5000 samples."]},{"cell_type":"code","metadata":{"id":"N8Y5cOHcl9ua","executionInfo":{"status":"ok","timestamp":1637198005194,"user_tz":300,"elapsed":401,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["params = list(gpt2.parameters()) + list(in_layer.parameters()) + list(out_layer.parameters())\n","optimizer = torch.optim.Adam(params)\n","loss_fn = nn.CrossEntropyLoss()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISJeoBw-l9ua","executionInfo":{"status":"ok","timestamp":1637198005491,"user_tz":300,"elapsed":2,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["for layer in (gpt2, in_layer, out_layer):\n","    layer.to(device=device)\n","    layer.train()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJD5hRXkl9ub","executionInfo":{"status":"ok","timestamp":1637198692115,"user_tz":300,"elapsed":683598,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"82c6d25e-e250-4884-8247-4938e1089ca8"},"source":["accuracies = [0]\n","while sum(accuracies[-50:]) / len(accuracies[-50:]) < .99:\n","    x, y = generate_example(n)\n","    x = torch.from_numpy(x).to(device=device, dtype=torch.long)\n","    y = torch.from_numpy(y).to(device=device, dtype=torch.long)\n","    \n","    embeddings = in_layer(x.reshape(1, -1))\n","    hidden_state = gpt2(inputs_embeds=embeddings).last_hidden_state[:,n:]\n","    logits = out_layer(hidden_state)[0]\n","    \n","    loss = loss_fn(logits, y)\n","    accuracies.append((logits.argmax(dim=-1) == y).float().mean().item())\n","    \n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if len(accuracies) % 500 == 0:\n","        accuracy = sum(accuracies[-50:]) / len(accuracies[-50:])\n","        print(f'Samples: {len(accuracies)}, Accuracy: {accuracy}')\n","\n","print(f'Final accuracy: {sum(accuracies[-50:]) / len(accuracies[-50:])}')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Samples: 500, Accuracy: 0.5120000118017196\n","Samples: 1000, Accuracy: 0.5360000133514404\n","Samples: 1500, Accuracy: 0.5760000118613243\n","Samples: 2000, Accuracy: 0.6720000129938125\n","Samples: 2500, Accuracy: 0.6360000106692314\n","Samples: 3000, Accuracy: 0.712000013589859\n","Samples: 3500, Accuracy: 0.7880000108480454\n","Samples: 4000, Accuracy: 0.9680000019073486\n","Final accuracy: 0.9920000004768371\n"]}]},{"cell_type":"markdown","metadata":{"id":"t-qubPfpl9ub"},"source":["## Visualizing attention map\n","\n","We can visualize the attention map of the first layer: the model learns to attend to the relevant bits for each element in the XOR operation.\n","Note the two consistent diagonal lines for output tokens 5-9 across samples, denoting each position of either string (the pattern is stronger if the model is allowed to train longer or evaluated on more samples)."]},{"cell_type":"code","metadata":{"id":"v-Bp47O4l9uc","executionInfo":{"status":"ok","timestamp":1637198789170,"user_tz":300,"elapsed":271,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}}},"source":["for layer in (gpt2, in_layer, out_layer):\n","    layer.eval()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cM04oCgl9uc","executionInfo":{"status":"ok","timestamp":1637198789323,"user_tz":300,"elapsed":6,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"5f783baa-7805-4978-9a9c-9783151b22fd"},"source":["bits, xor = generate_example(n)\n","\n","with torch.no_grad():\n","    x = torch.from_numpy(bits).to(device=device, dtype=torch.long)\n","    \n","    embeddings = in_layer(x)\n","    transformer_outputs = gpt2(\n","        inputs_embeds=embeddings,\n","        return_dict=True,\n","        output_attentions=True,\n","    )\n","    logits = out_layer(transformer_outputs.last_hidden_state[n:])\n","    predictions = logits.argmax(dim=-1).cpu().numpy()\n","\n","print('  String 1:', bits[:n])\n","print('  String 2:', bits[n:])\n","print('Prediction:', predictions)\n","print('Output XOR:', xor)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["  String 1: [0 0 0 1 0]\n","  String 2: [1 1 0 1 0]\n","Prediction: [1 1 0 0 0]\n","Output XOR: [1 1 0 0 0]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301},"id":"ptbhfEY9l9ud","executionInfo":{"status":"ok","timestamp":1637198789579,"user_tz":300,"elapsed":259,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"1cb83bef-2442-446d-f951-bb975773103e"},"source":["attentions = transformer_outputs.attentions[0][0]  # first layer, first in batch\n","mean_attentions = attentions.mean(dim=0)           # take the mean over heads\n","mean_attentions = mean_attentions.cpu().numpy()\n","\n","plt.xlabel('Input Tokens', size=16)\n","plt.xticks(range(10), bits)\n","plt.ylabel('Output Tokens', size=16)\n","plt.yticks(range(10), ['*'] * 5 + list(predictions))\n","\n","plt.imshow(mean_attentions)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f35127f8a50>"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"4YIXXXKGl9ud"},"source":["## Sanity check\n","\n","As a sanity check, we can see that the model could solve this task without needing to finetune the self-attention layers! The XOR was computed using only the connections already present in GPT-2."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_8ZL9yBl9ud","executionInfo":{"status":"ok","timestamp":1637198792534,"user_tz":300,"elapsed":2373,"user":{"displayName":"Alex Chin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12032306213621245608"}},"outputId":"cf6aa8ce-b8b6-4f25-f287-b895dc689142"},"source":["fresh_gpt2 = GPT2Model.from_pretrained('gpt2')\n","\n","gpt2.to(device='cpu')\n","gpt2_state_dict = gpt2.state_dict()\n","for name, param in fresh_gpt2.named_parameters():\n","    if 'attn' in name or 'mlp' in name:\n","        new_param = gpt2_state_dict[name]\n","        if torch.abs(param.data - new_param.data).sum() > 1e-8:\n","            print(f'{name} was modified')\n","        else:\n","            print(f'{name} is unchanged')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["h.0.attn.c_attn.weight is unchanged\n","h.0.attn.c_attn.bias is unchanged\n","h.0.attn.c_proj.weight is unchanged\n","h.0.attn.c_proj.bias is unchanged\n","h.0.mlp.c_fc.weight is unchanged\n","h.0.mlp.c_fc.bias is unchanged\n","h.0.mlp.c_proj.weight is unchanged\n","h.0.mlp.c_proj.bias is unchanged\n","h.1.attn.c_attn.weight is unchanged\n","h.1.attn.c_attn.bias is unchanged\n","h.1.attn.c_proj.weight is unchanged\n","h.1.attn.c_proj.bias is unchanged\n","h.1.mlp.c_fc.weight is unchanged\n","h.1.mlp.c_fc.bias is unchanged\n","h.1.mlp.c_proj.weight is unchanged\n","h.1.mlp.c_proj.bias is unchanged\n","h.2.attn.c_attn.weight is unchanged\n","h.2.attn.c_attn.bias is unchanged\n","h.2.attn.c_proj.weight is unchanged\n","h.2.attn.c_proj.bias is unchanged\n","h.2.mlp.c_fc.weight is unchanged\n","h.2.mlp.c_fc.bias is unchanged\n","h.2.mlp.c_proj.weight is unchanged\n","h.2.mlp.c_proj.bias is unchanged\n","h.3.attn.c_attn.weight is unchanged\n","h.3.attn.c_attn.bias is unchanged\n","h.3.attn.c_proj.weight is unchanged\n","h.3.attn.c_proj.bias is unchanged\n","h.3.mlp.c_fc.weight is unchanged\n","h.3.mlp.c_fc.bias is unchanged\n","h.3.mlp.c_proj.weight is unchanged\n","h.3.mlp.c_proj.bias is unchanged\n","h.4.attn.c_attn.weight is unchanged\n","h.4.attn.c_attn.bias is unchanged\n","h.4.attn.c_proj.weight is unchanged\n","h.4.attn.c_proj.bias is unchanged\n","h.4.mlp.c_fc.weight is unchanged\n","h.4.mlp.c_fc.bias is unchanged\n","h.4.mlp.c_proj.weight is unchanged\n","h.4.mlp.c_proj.bias is unchanged\n","h.5.attn.c_attn.weight is unchanged\n","h.5.attn.c_attn.bias is unchanged\n","h.5.attn.c_proj.weight is unchanged\n","h.5.attn.c_proj.bias is unchanged\n","h.5.mlp.c_fc.weight is unchanged\n","h.5.mlp.c_fc.bias is unchanged\n","h.5.mlp.c_proj.weight is unchanged\n","h.5.mlp.c_proj.bias is unchanged\n","h.6.attn.c_attn.weight is unchanged\n","h.6.attn.c_attn.bias is unchanged\n","h.6.attn.c_proj.weight is unchanged\n","h.6.attn.c_proj.bias is unchanged\n","h.6.mlp.c_fc.weight is unchanged\n","h.6.mlp.c_fc.bias is unchanged\n","h.6.mlp.c_proj.weight is unchanged\n","h.6.mlp.c_proj.bias is unchanged\n","h.7.attn.c_attn.weight is unchanged\n","h.7.attn.c_attn.bias is unchanged\n","h.7.attn.c_proj.weight is unchanged\n","h.7.attn.c_proj.bias is unchanged\n","h.7.mlp.c_fc.weight is unchanged\n","h.7.mlp.c_fc.bias is unchanged\n","h.7.mlp.c_proj.weight is unchanged\n","h.7.mlp.c_proj.bias is unchanged\n","h.8.attn.c_attn.weight is unchanged\n","h.8.attn.c_attn.bias is unchanged\n","h.8.attn.c_proj.weight is unchanged\n","h.8.attn.c_proj.bias is unchanged\n","h.8.mlp.c_fc.weight is unchanged\n","h.8.mlp.c_fc.bias is unchanged\n","h.8.mlp.c_proj.weight is unchanged\n","h.8.mlp.c_proj.bias is unchanged\n","h.9.attn.c_attn.weight is unchanged\n","h.9.attn.c_attn.bias is unchanged\n","h.9.attn.c_proj.weight is unchanged\n","h.9.attn.c_proj.bias is unchanged\n","h.9.mlp.c_fc.weight is unchanged\n","h.9.mlp.c_fc.bias is unchanged\n","h.9.mlp.c_proj.weight is unchanged\n","h.9.mlp.c_proj.bias is unchanged\n","h.10.attn.c_attn.weight is unchanged\n","h.10.attn.c_attn.bias is unchanged\n","h.10.attn.c_proj.weight is unchanged\n","h.10.attn.c_proj.bias is unchanged\n","h.10.mlp.c_fc.weight is unchanged\n","h.10.mlp.c_fc.bias is unchanged\n","h.10.mlp.c_proj.weight is unchanged\n","h.10.mlp.c_proj.bias is unchanged\n","h.11.attn.c_attn.weight is unchanged\n","h.11.attn.c_attn.bias is unchanged\n","h.11.attn.c_proj.weight is unchanged\n","h.11.attn.c_proj.bias is unchanged\n","h.11.mlp.c_fc.weight is unchanged\n","h.11.mlp.c_fc.bias is unchanged\n","h.11.mlp.c_proj.weight is unchanged\n","h.11.mlp.c_proj.bias is unchanged\n"]}]},{"cell_type":"code","metadata":{"id":"J0nAkAJtpvz1"},"source":[""],"execution_count":null,"outputs":[]}]}